{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('QueryResults .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27182"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data) # the number of extracted questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;I want to use a track-bar to change a form'...</td>\n",
       "      <td>&lt;c#&gt;&lt;floating-point&gt;&lt;type-conversion&gt;&lt;double&gt;&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>&lt;p&gt;I have an absolutely positioned &lt;code&gt;div&lt;/...</td>\n",
       "      <td>&lt;html&gt;&lt;css&gt;&lt;css3&gt;&lt;internet-explorer-7&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>&lt;p&gt;An explicit cast to double like this isn't ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>&lt;p&gt;Given a &lt;code&gt;DateTime&lt;/code&gt; representing ...</td>\n",
       "      <td>&lt;c#&gt;&lt;.net&gt;&lt;datetime&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>&lt;p&gt;Given a specific &lt;code&gt;DateTime&lt;/code&gt; valu...</td>\n",
       "      <td>&lt;c#&gt;&lt;datetime&gt;&lt;time&gt;&lt;datediff&gt;&lt;relative-time-s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               Body  \\\n",
       "0   4  <p>I want to use a track-bar to change a form'...   \n",
       "1   6  <p>I have an absolutely positioned <code>div</...   \n",
       "2   7  <p>An explicit cast to double like this isn't ...   \n",
       "3   9  <p>Given a <code>DateTime</code> representing ...   \n",
       "4  11  <p>Given a specific <code>DateTime</code> valu...   \n",
       "\n",
       "                                                Tags  \n",
       "0  <c#><floating-point><type-conversion><double><...  \n",
       "1             <html><css><css3><internet-explorer-7>  \n",
       "2                                                NaN  \n",
       "3                               <c#><.net><datetime>  \n",
       "4  <c#><datetime><time><datediff><relative-time-s...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() # preview data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_avant=defaultdict(list)\n",
    "for i in data.index:\n",
    "    cor_avant[data.iloc[i,0]]=nltk.word_tokenize(data.iloc[i,1])\n",
    "frequency={}\n",
    "for key,val in cor_avant.items():\n",
    "    frequency[key]=nltk.FreqDist(val)\n",
    "counter_av=nltk.Counter()\n",
    "for key,val in cor_avant.items():\n",
    "    counter_av+=frequency[key]\n",
    "nb_mot_initial=len(counter_av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=nltk.RegexpTokenizer(r'\\w+') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora=defaultdict(list) # world list used for each id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.index:\n",
    "    corpora[data.iloc[i,0]]=tokenizer.tokenize(data.iloc[i,1].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<p>I want to use a track-bar to change a form's opacity.</p>\\n\\n<p>This is my code:</p>\\n\\n<pre><code>decimal trans = trackBar1.Value / 5000;\\nthis.Opacity = trans;\\n</code></pre>\\n\\n<p>When I build the application, it gives the following error:</p>\\n\\n<blockquote>\\n  <p>Cannot implicitly convert type <code>'decimal'</code> to <code>'double'</code>.</p>\\n</blockquote>\\n\\n<p>I tried using <code>trans</code> and <code>double</code> but then the control doesn't work. This code worked fine in a past VB.NET project.</p>\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# illustration in the first question of our data set.\n",
    "texte=data.iloc[0,1]\n",
    "texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p,i,want,to,use,a,track,bar,to,change,a,form,s,opacity,p,p,this,is,my,code,p,pre,code,decimal,trans,trackbar1,value,5000,this,opacity,trans,code,pre,p,when,i,build,the,application,it,gives,the,following,error,p,blockquote,p,cannot,implicitly,convert,type,code,decimal,code,to,code,double,code,p,blockquote,p,i,tried,using,code,trans,code,and,code,double,code,but,then,the,control,doesn,t,work,this,code,worked,fine,in,a,past,vb,net,project,p'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first texte after tokenization\n",
    "tock_texte=corpora[4]\n",
    "tock_texte=(',').join(tock_texte)\n",
    "tock_texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import EnglishStemmer\n",
    "stemmer=EnglishStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming worlds.\n",
    "for key,val in corpora.items():\n",
    "    corpora[key]=[stemmer.stem(w) for w in val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p,i,want,to,use,a,track,bar,to,chang,a,form,s,opac,p,p,this,is,my,code,p,pre,code,decim,tran,trackbar1,valu,5000,this,opac,tran,code,pre,p,when,i,build,the,applic,it,give,the,follow,error,p,blockquot,p,cannot,implicit,convert,type,code,decim,code,to,code,doubl,code,p,blockquot,p,i,tri,use,code,tran,code,and,code,doubl,code,but,then,the,control,doesn,t,work,this,code,work,fine,in,a,past,vb,net,project,p'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first texte after the Stemming operation.\n",
    "stemm_texte=corpora[4]\n",
    "stemm_texte=(',').join(stemm_texte)\n",
    "stemm_texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of world\n",
    "freq=dict()\n",
    "for key,val in corpora.items():\n",
    "    freq[key]=nltk.FreqDist(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop of words \n",
    "counter=nltk.Counter()\n",
    "for k,v in corpora.items():\n",
    "    counter+=freq[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will classify the 100 most used words as stop of word.\n",
    "most_freq=[a[0] for a in counter.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will create a set which cumulate the 100 most used words and the stop words list belong to the library NLTK.\n",
    "sw=set() \n",
    "sw.update(most_freq)\n",
    "sw.update(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete stop of words from our corpus.\n",
    "for k,v in corpora.items():\n",
    "    corpora[k]=[w for w in v if w not in list(sw) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'track,bar,chang,form,opac,decim,tran,trackbar1,valu,5000,opac,tran,build,give,follow,error,blockquot,cannot,implicit,convert,type,decim,doubl,blockquot,tri,tran,doubl,control,fine,past,vb,project'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first texte after deleting stop of words.\n",
    "stop_texte=corpora[4]\n",
    "stop_texte=(',').join(stop_texte)\n",
    "stop_texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recomputing the statistics of bag of words after deleting the stop of words.\n",
    "for k,v in corpora.items():\n",
    "    freq[k]=nltk.FreqDist(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'tran': 3, 'opac': 2, 'decim': 2, 'blockquot': 2, 'doubl': 2, 'track': 1, 'bar': 1, 'chang': 1, 'form': 1, 'trackbar1': 1, ...})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#illustration of the bag of words for the choiced texte.\n",
    "bag_texte=freq[4]\n",
    "bag_texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparaison to the number of terms used before and after cleaning.\n",
    "count_ap=nltk.Counter()\n",
    "for k,v in freq.items():\n",
    "    count_ap+=freq[k]\n",
    "nb_mot_apres=len(count_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avant nettoyage</th>\n",
       "      <th>Apres nettoyage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Vocabulaires</th>\n",
       "      <td>116108</td>\n",
       "      <td>53966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Avant nettoyage   Apres nettoyage \n",
       "Vocabulaires            116108             53966"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparatives=pd.DataFrame({'Avant nettoyage ':[nb_mot_initial],'Apres nettoyage ':[nb_mot_apres]},index=['Vocabulaires'])\n",
    "comparatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data based on bags of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_val=list(corpora.values())\n",
    "cor_user=[]\n",
    "for elt in cor_val:\n",
    "    cor_user.append(\" \".join(elt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function allow to compute the frequency of used words per document.\n",
    "sk=CountVectorizer(max_df=0.95,min_df=2,lowercase=False,stop_words='english').fit(cor_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor=sk.transform(cor_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor=cor.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data based on TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function allow to compute the tf-idf for each used word per document.\n",
    "Tfidf=TfidfVectorizer(max_df=0.95,min_df=2,lowercase=False,stop_words='english').fit(cor_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_tfidf=Tfidf.transform(cor_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the list index where Tags values  are missing.\n",
    "ind_missing=np.where(data['Tags'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete all rows from defined dataframe where rows Tags are missing.\n",
    "cor=cor[~ind_missing[0],:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete all rows from defined dataframe where rows Tags are missing.\n",
    "cor_tfidf=cor_tfidf[~ind_missing[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    " tags=data['Tags'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_tag=[]\n",
    "for elt in tags:\n",
    "    texte=str()\n",
    "    for ind in elt:\n",
    "        texte+=ind\n",
    "        if ind=='>':\n",
    "            texte+=\" \"\n",
    "    cor_tag.append(texte)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk=CountVectorizer(lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_target=mk.fit_transform(cor_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_target=cor_target.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_q=len(cor_target)\n",
    "app_mot=[]\n",
    "for i in range(cor_target.shape[1]):\n",
    "    app_mot.append(cor_target[:,i].sum()/nb_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=np.argsort(app_mot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_target=[100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,2425]\n",
    "question=[]\n",
    "for i in selected_target:\n",
    "    a=len(np.where(cor_target[:,index[-i-1:-1]].any(axis=1))[0])\n",
    "    question.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81576552, 0.89204442, 0.926998  , 0.94301839, 0.95357728,\n",
       "       0.95940288, 0.96431822, 0.96868742, 0.97232842, 0.97542327,\n",
       "       0.97687967, 0.97778991, 0.97924631, 0.98015656, 0.98106681,\n",
       "       0.98798471])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=np.array(question)/cor_target.shape[0]\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tags=100 # we choice the number tags which allow to maintain 80% of question ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2425"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_target.shape[1]# total number of tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar=cor_target[:,index[-101:-1]] # we save only the choiced target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar=tar[np.where(tar.any(axis=1))[0],:] # we save only the question which have tagets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4481, 100)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=[]\n",
    "for a in index[-101:-1]:\n",
    "    col.append(mk.get_feature_names()[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=pd.DataFrame(tar,columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf=cor_tfidf[np.where(tar.any(axis=1))[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf=pd.DataFrame(df_tfidf.toarray(),columns=Tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor=cor[np.where(tar.any(axis=1))[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(cor,columns=sk.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('bags_words.csv')\n",
    "df_tfidf.to_csv('tfidf.csv')\n",
    "target.to_csv('target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=os.path.abspath(os.path.dirname('__file__'))\n",
    "chemin=os.path.join(path,'utiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(chemin,'wb') as fichier:\n",
    "    mon_pickler=pickle.Pickler(fichier)\n",
    "    mon_pickler.dump(most_freq)\n",
    "    mon_pickler.dump(sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
